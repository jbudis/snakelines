Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 3
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	2	nanoplot__quality_report
	1	nanoplot_summary_report
	1	pipeline
	4

[Wed Dec 16 11:15:11 2020]
rule nanoplot_summary_report:
    input: reads/original/example_1.fastq, reads/original/example_2.fastq
    output: reads/original/stats/summary.html
    jobid: 3
    reason: Missing output files: reads/original/stats/summary.html
    wildcards: read_type=original
    threads: 3


        mkdir reads/original/stats/tmp

        NanoPlot             --outdir reads/original/stats/tmp             --threads 3             --fastq reads/original/example_1.fastq reads/original/example_2.fastq             --plots hex dot

        mv reads/original/stats/tmp/NanoPlot-report.html reads/original/stats/summary.html
        rm -r reads/original/stats/tmp
        
[Wed Dec 16 11:15:44 2020]
Error in rule nanoplot_summary_report:
    jobid: 3
    output: reads/original/stats/summary.html
    shell:
        
        mkdir reads/original/stats/tmp

        NanoPlot             --outdir reads/original/stats/tmp             --threads 3             --fastq reads/original/example_1.fastq reads/original/example_2.fastq             --plots hex dot

        mv reads/original/stats/tmp/NanoPlot-report.html reads/original/stats/summary.html
        rm -r reads/original/stats/tmp
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/adog/snakelines/example/nanomap/.snakemake/log/2020-12-16T111511.547829.snakemake.log
