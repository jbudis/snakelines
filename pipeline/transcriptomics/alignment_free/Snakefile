# Load configuration file
configfile: srcdir('config.yaml')

# Run startup scripts that automatically loads imports from src/ and load helper methods
include: config['snakelines_dir'] + '/src/snakelines.snake'

# Import sub-workflows
include: srcdir('Snakefile.read_quality_report')
include: srcdir('Snakefile.preprocess')

table_formats = ['xlsx', 'tsv']
pca_formats = extract_from_config(config, ['classification', 'report', 'transcripts', 'pca', 'formats'], ['png'])

rule finalise__classify_transcripts:
    """
    Pipeline classify preprocess reads against chosen reference sequences. According to their taxonomic labels,
    number of reads per taxonomic units are summarized into graphical and tabular reports.
    :input abundances: summary tables with number of reads mapped to transcripts
    :output abundances: summary tables with number of reads mapped to transcripts (in the report directory)
    """
    input:
        rules.finalise__quality_report.output,
        rules.finalise__preprocess_reads.output,

        abundances = expand('classification/{reference}/report/tsv/summary.{format}',
                             reference=pipeline.references, format=table_formats),

        pcas = expand('classification/{reference}/report/comparison/pca.{format}',
                             reference=pipeline.references, format=pca_formats),

        de_tables = expand('classification/{reference}/report/comparison/differential_analysis.tsv',
                            reference=pipeline.references)

    output:
        abundances = expand('{report_dir}/{reference}/tsv/summary.{format}',
                             report_dir=config['report_dir'], reference=pipeline.references, format=de_formats),

        pcas = expand('{report_dir}/{reference}/comparison/pca.{format}',
                       report_dir=config['report_dir'], reference=pipeline.references, format=pca_formats),

        de_tables = expand('{report_dir}/{reference}/comparison/differential_analysis.tsv',
                            report_dir=config['report_dir'], reference=pipeline.references),

    run:
        copy_input_files_with_consistent_output_names(input, output)

# Target rule would be executed locally, not on cluster
localrules: finalise__classify_transcripts