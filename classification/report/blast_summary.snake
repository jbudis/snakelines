from Bio.Blast import NCBIXML
from Bio import SeqIO
import os

import pandas as pd
pd.set_option('display.max_colwidth', 1000000)
pd.options.display.float_format = '{:.1f}'.format

TEMPLATE = open(srcdir('templates/abundances.html')).read()

n_contigs = int(config['blast']['report']['max_query_seqs'])

rule blast_summary:
    input:
        contigs = '{indir}/{name}.fasta',
        blast = '{indir}/blast/{name}.blast'
    output:
        report = '{indir}/blast/{name}.html'
    params:
        contig_dir = '{indir}/blast/individual'
    run:

        # Split contigs.fasta file into separate fasta files, one for each contig - downloadable from HTML page
        if not os.path.exists(params.contig_dir):
            os.mkdir(params.contig_dir)

        for i, contig in enumerate(SeqIO.parse(input.contigs, 'fasta')):
            with open('%s/%s.fa' % (params.contig_dir, contig.id), 'w') as out:
                SeqIO.write(contig, out, 'fasta')
            if i >= n_contigs:
                break

        # Calculation of query/target overlap
        def deduplicate(intervals):
            dedup = []
            for start, end in sorted(intervals):
                if dedup and dedup[-1][1] >= start - 1:
                    dedup[-1][1] = max(dedup[-1][1], end)
                else:
                    dedup.append([start, end])

            return dedup

        def calc_align_len(alignment):
            intervals = deduplicate([(hsp.query_start, hsp.query_end) for hsp in alignment.hsps])
            return sum(end - start + 1 for start, end in intervals)

        # Collect Blast results
        contig_items = []
        with open(input.blast) as blast_results:
            for i, contig in enumerate(NCBIXML.parse(blast_results)):

                contig_link = '<a href="individual/%s.fa">%s</a>' % (contig.query, contig.query)

                contig_len = contig.query_length
                aligns = contig.alignments
                align_lens = map(calc_align_len, aligns)
                titles = [align.title for align in aligns]
                gbids = [title.split('|')[3] for title in titles]
                names = [title.split('|')[-1] for title in titles]
                links = []
                for gbid, name, align_len in zip(gbids, names, align_lens):
                    coverage = align_len / contig_len
                    links.append('%3.2f%% - <a href="https://www.ncbi.nlm.nih.gov/nuccore/%s">%s</a>' % \
                                  (coverage * 100, gbid, name))

                is_unicycler = 'depth=' in contig.query
                if is_unicycler:
                    coverage = float(contig.query.split('depth=')[1].split('x')[0])
                else:
                    coverage = float(contig.query.split('_')[5])


                contig_info = {'Contig': contig_link,
                               'Homologues': '<br/>'.join(links),
                               'Length': contig_len,
                               'Coverage': coverage}

                contig_items.append(contig_info)

                if i >= n_contigs:
                    break

        # Generate report
        columns = ['Contig', 'Length', 'Coverage', 'Homologues']
        contigs = pd.DataFrame(contig_items)[columns]
        contigs_table = contigs.to_html(escape=False).replace('<table ', '<table id="data" ')

        with open(output.report, 'w') as out:
            out.write(TEMPLATE.format(contigs_table=contigs_table))