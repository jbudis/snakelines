include: config['snakelines_dir'] + '/rules/reference/annotation/regions.snake'
# include: config['snakelines_dir'] + '/rules/mapping/index/samtools.snake'
include: config['snakelines_dir'] + '/rules/reference/index/fai/samtools.snake'
include: config['snakelines_dir'] + '/rules/reference/index/dict/picard.snake'

rule gatk__fix_vcf_header:
    """
    Adds missing sequence dictionary to VCF header. This job also generates VCF index (.idx).
    :input vcf: Raw VCF from variant caller vardict.
    :input fasta: Reference sequence.
    :output vcf: Fixed VCF.
    :output vcf_index: Fixed VCF index.
    """
    input:
        vcf = 'variant/{reference}-{panel}/original/{sample}.vardict.vcf',
        fasta = 'reference/{reference}/{reference}.fa'
    output:
        vcf = 'variant/{reference}-{panel}/original/{sample}.vcf',
        vcf_index = 'variant/{reference}-{panel}/original/{sample}.vcf.idx',
    log:
        out = 'variant/{reference}-{panel}/original/log/{sample}.out',
        err = 'variant/{reference}-{panel}/original/log/{sample}.err',
    conda:
        config['snakelines_dir'] + '/enviroments/others_env.yaml'
    shell:
        """
        gatk SelectVariants \
            -V {input.vcf} \
            -R {input.fasta} \
            -O {output.vcf} \
            1>{log.out} \
            2>{log.err}
        """

rule vardict__create_wgs_bed_file:
    """
    Creates bed file with whole genomic regions in reference fasta file. Simple way to unite WGS and panel analysis.
    """
    input:
        fai = 'reference/{reference}/{reference}.fa.fai'
    output:
        bed = 'reference/{reference}/annotation/wgs/regions.bed'
    shell:
          """
        awk \
            '{{print $1, 1, $2, $1}}' \
      {input.fai} \
              | sed \
              's/ /\t/g' \
              > {output.bed}
              """

rule vardict__prepare_bed_file:
    """
    Vardict throws error for bed files with more than 4 columns, rule therefore cut other columns
    """
    input:
        bed = 'reference/{reference}/annotation/{panel}/regions.bed',
    output:
        bed = 'reference/{reference}/annotation/{panel}/regions.vardict.bed',
    shell:
        """
        cut -f 1-4 {input.bed} > {output.bed}
        """

# TODO variants should be stored in "original" folder
rule vardict__call_germline_variants:
    """
    Identify small variation (SNP and indels) from the mapped reads.
    """
    input:
        bam      = 'mapping/{reference}/%s/{sample}.bam' % pipeline.postprocessed_map_type,
        bai      = 'mapping/{reference}/%s/{sample}.bam.bai' % pipeline.postprocessed_map_type,
        bed      = 'reference/{reference}/annotation/{panel}/regions.vardict.bed',
        reffasta = 'reference/{reference}/{reference}.fa',
        reffaidx = 'reference/{reference}/{reference}.fa.fai'
    output:
        vdc = temp('variant/{reference}-{panel}/original/{sample}.vdc')
    log:
        err      = 'variant/{reference}-{panel}/original/log/{sample}.vdc.err'
    params:
        min_nonref_allele_freq = method_config.get('hard_filter', {}).get('min_nonref_allele_freq', 0.05),
        min_alternate_count    = method_config.get('hard_filter', {}).get('min_alternate_count', 2),
        min_map_quality        = method_config.get('hard_filter', {}).get('min_map_quality', 15)
    threads:
        int(config['threads'])
    conda:
        config['snakelines_dir'] + '/enviroments/vardict-java.yaml'
    shell:
        """
        vardict-java \
            -G {input.reffasta} \
            -b {input.bam} \
            -f {params.min_nonref_allele_freq} \
            -r {params.min_alternate_count} \
            -Q {params.min_map_quality} \
            -th {threads} \
            -c 1 \
            -S 2 \
            -E 3 \
            -g 4 \
            {input.bed} \
        >  {output.vdc} \
        2> {log.err}
        """

# TODO hardcoded path
rule vardict__test_strand_bias:
    """
    Perform statistical testing of strand bias.
    """
    input:
        vdc = 'variant/{reference}-{panel}/original/{sample}.vdc'
    output:
        tsb = temp('variant/{reference}-{panel}/original/{sample}.tsb')
    log:
        err = 'variant/{reference}-{panel}/original/log/{sample}.test_strand_bias.err'
    conda:
        config['snakelines_dir'] + '/enviroments/vardict.yaml'
    shell:
        """
        cat {input.vdc} \
        | teststrandbias.R \
        >  {output.tsb} \
        2> {log.err}
        """

# TODO hardcoded path
rule vardict__tsb_to_vcf:
    """
    Convert intermediate files of Vardict to VCF format
    """
    input:
        tsb = 'variant/{reference}-{panel}/original/{sample}.tsb'
    output:
        vcf = temp('variant/{reference}-{panel}/original/{sample}.vardict.vcf')
    params:
        min_mean_base_quality  = method_config.get('soft_filter', {}).get('min_mean_base_quality', 20),
        min_map_quality        = method_config.get('soft_filter', {}).get('min_map_quality', 20),
        read_depth             = method_config.get('soft_filter', {}).get('read_depth', 10),
        min_nonref_allele_freq = method_config.get('soft_filter', {}).get('min_nonref_allele_freq', 0.2)
    conda:
        config['snakelines_dir'] + '/enviroments/vardict.yaml'
    shell:
        """
        var2vcf_valid.pl \
            -S \
            -A \
            -q {params.min_mean_base_quality} \
            -Q {params.min_map_quality} \
            -d {params.read_depth} \
            -f {params.min_nonref_allele_freq}  \
            -N {wildcards.sample} \
            {input} \
        > {output}
        """
