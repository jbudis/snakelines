include: config['snakelines_dir'] + '/rules/reads/conversion/unzip.snake'

rule fastuniq__deduplicate_reads:
    """
    Remove fragments with identical sequences that are usually consequence of extensive PCR multiplication
    :input r1: Left side of sequenced fragments in gzipped fastq format
    :input r2: Right side of sequenced fragments in gzipped fastq format
    :output r1: Left side of fragments without duplications in gzipped fastq format
    :output r2: Right side of fragments without duplications in gzipped fastq format
    :output pair_description: Auxiliary file with names for paired files
    :output unzipped_r1: Auxiliary file with unzipped left side of sequenced fragments
    :output unzipped_r2: Auxiliary file with unzipped right side of sequenced fragments
    """
    input:
        r1 = 'reads/%s/{sample}_R1.fastq' % method_config['input_read_type'],
        r2 = 'reads/%s/{sample}_R2.fastq' % method_config['input_read_type']
    output:
        r1 = configured_temp('reads/deduplicated/{sample}_R1.fastq.gz'),
        r2 = configured_temp('reads/deduplicated/{sample}_R2.fastq.gz'),
        pair_description = temp('reads/deduplicated/{sample}.txt'),
        unzipped_r1 = temp('reads/deduplicated/{sample}_R1.fastq'),
        unzipped_r2 = temp('reads/deduplicated/{sample}_R2.fastq')
    conda:
        config['snakelines_dir'] + '/enviroments/fastuniq.yaml'
    shell:
        """
        echo "{input.r1}\n{input.r2}" > {output.pair_description}

        fastuniq \
            -i {output.pair_description} \
            -o {output.unzipped_r1} \
            -p {output.unzipped_r2}

        gzip --keep {output.unzipped_r1}
        gzip --keep {output.unzipped_r2}
        """


    
