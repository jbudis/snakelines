include: config['snakelines_dir'] + '/rules/reads/conversion/unzip.snake'

rule fastuniq__deduplicate_reads:
    '''
    Remove fragments with identical sequences that are usually consequence of extensive PCR multiplication
    '''
    input:
        r1 = 'reads/%s/{sample}_R1.fastq' % method_config['input_read_type'],
        r2 = 'reads/%s/{sample}_R2.fastq' % method_config['input_read_type']
    output:
        r1 = configured_temp('reads/deduplicated/{sample}_R1.fastq.gz'),
        r2 = configured_temp('reads/deduplicated/{sample}_R2.fastq.gz'),
        pair_description = temp('reads/deduplicated/{sample}.txt'),
        unzipped_r1 = temp('reads/deduplicated/{sample}_R1.fastq'),
        unzipped_r2 = temp('reads/deduplicated/{sample}_R2.fastq')
    shell:
        '''
        echo "{input.r1}\n{input.r2}" > {output.pair_description}

        fastuniq \
            -i {output.pair_description} \
            -o {output.unzipped_r1} \
            -p {output.unzipped_r2}

        gzip --keep {output.unzipped_r1}
        gzip --keep {output.unzipped_r2}
        '''


    
