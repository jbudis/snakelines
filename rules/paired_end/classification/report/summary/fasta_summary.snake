# TODO: this source should be thoroughly documented
# TODO: method_config should be renamed to method_config

import subprocess
import snakemake
import os
import shutil
import numpy as np
import pickle
import pandas as pd
import zlib
pd.set_option('display.max_colwidth', 1000000)
pd.options.display.float_format = '{:.3f}'.format

DEFAULT_MAX_TARGET_SEQS = 10

summary_columns_def = method_config.get('include', [])
if not summary_columns_def:
    summary_columns_def = []

include_coverage  = 'coverage'  in summary_columns_def
include_virfinder = 'virfinder' in summary_columns_def
include_blast     = 'blast'     in summary_columns_def

if include_blast:
    # TODO: change extract_from_config to something like config_for_method('blast')
    blast_references = list(extract_from_config(config, ['classification', 'contig_based', 'reference'], {}).keys())

rule fasta_summary__blast:
    """
    Convert blast results into standardised unified format for fasta summary generation
    :input blast: Blast classification with taxonomy
    :output tsv: Classification in unified format
    """
    input:
        blast = '{indir}/blast/{reference}/{name}.blast.tax.tsv'
    output:
        tsv   = '{indir}/annotation/{name}/attributes/blast/{reference}.blast.tsv'
    params:
        script_path = srcdir('scripts/fasta_summary_blast.py'),
        min_query_coverage = method_config.get('min_query_coverage', 0),
        max_target_seqs = method_config.get('max_target_seqs', 999999999)
    conda:
        config['snakelines_dir'] + '/enviroments/fasta_summary.yaml'
    shell:
        """
        python3 {params.script_path}\
            {input.blast}\
            {params.min_query_coverage}\
            {params.max_target_seqs}\
            {output.tsv}
        """
        

rule fasta_summary__coverage:
    """
    Extract mapping coverage and store it into standardised unified format for fasta summary generation
    :input qualimap: Quality report statistics generated by Qualimap
    :output tsv: Mapping coverage in standardised unified format for fasta summary generation
    """
    input:
        qualimap = '{indir}/mapping/stats-{panel}/{name}/genome_results.txt',
    output:
        tsv      = '{indir}/annotation/{name}/attributes/coverage.tsv'
    params:
        script_path = srcdir('scripts/fasta_summary_blast.py'),
    conda:
        config['snakelines_dir'] + '/enviroments/fasta_summary.yaml'
    shell:
        """
        python3 {params.script_path}\
            {input.qualimap}\
            {output.tsv}
        """
        

rule fasta_summary__mapped_reads:
    """
    Get number of mapped reads to each reference sequence and convert into standardised unified format for
    fasta summary generation
    :input bam: Mapped reads in bam format
    :input bai: Index for bam file with mapped reads
    :output tsv: Mapped reads per reference sequence in standardised unified format for fasta summary generation
    """
    input:
        bam = '{indir}/mapping/{name}.bam',
        bai = '{indir}/mapping/{name}.bam.bai'
    output:
        tsv = '{indir}/annotation/{name}/attributes/mapped_reads.tsv'
    conda:
        config['snakelines_dir'] + '/enviroments/samtools.yaml'
    shell:
        """
        echo -e '\tMapped reads' > {output.tsv}
        samtools idxstats {input.bam} | cut -f 1,3 | grep -v '*' > {output.tsv}
        """

rule fasta_summary__virfinder:
    input:
        pvalues   = '{indir}/virfinder/{name}.pvalues.tsv'
    output:
        tsv       = '{indir}/annotation/{name}/attributes/virfinder.tsv'
    params:
        script_path = srcdir('scripts/fasta_summary_virfinder.py')
    conda:
        config['snakelines_dir'] + '/enviroments/fasta_summary.yaml'
    shell:
        """
        python3 {params.script_path}\
            {input.pvalues}\
            {output.tsv}
        """


# TODO documentation
rule fasta_summary__copy_contigs:
    """
    Separate sequences into individual fasta files and calculate basic statistics for each sequence.
    Also store statistics into standardised unified format for fasta summary generation.
    :input fasta: Genomic sequences in fasta format
    :output fasta: Copy of fasta file, stored in the directory accessible from summary HTML report
    :output seqinfo: Statistics of genomic sequences in standardised unified format for fasta summary generation
    """
    input:
        fasta     = '{indir}/{name}.fa'
    output:
        fasta_dir = directory('{indir}/annotation/{name}/sequences/'),
        seqinfo   = '{indir}/annotation/{name}/attributes/seqinfo.fa'
    params:
        script_path = srcdir('scripts/fasta_summary_contigs.py'),
        fasta     = '{indir}/annotation/{name}/sequences/all_contigs.fa',
    conda:
        config['snakelines_dir'] + '/enviroments/fasta_summary.yaml'
    shell:
        """
        python3 {params.script_path}\
            {input.fasta}\
            {params.fasta}\
            {output.fasta_dir}\
            {output.seqinfo}
        """


def blast_attr_tsvs(wildcards):
    return expand('{indir}/annotation/{name}/attributes/blast/{reference}.blast.tsv',
                   indir=wildcards.indir, name=wildcards.name, reference=blast_references)

rule fasta_summary__summarize_annotations:
    """
    Generate summary HTML report with several aggregated attribute sources from various tools.
    :input template: HTML template with basic report outline
    :input fasta: Analysed sequences in fasta format
    :input attrs_seqinfo: Basic statistics of genomic sequences - length, GC content, complexity...
    :input attrs_coverage: Mapping coverage of sequences
    :input attrs_mapped_reads: Mapped reads per genomic sequence
    :input attrs_virfinder: Probabilities of viral origin for genomic sequences - calculated by the Virfinder tool
    """
    input:
        # Required files to generate blast summary
        template = srcdir('templates/abundances.html'),
        fasta_dir       = '{indir}/annotation/{name}/sequences/',
        attrs_seqinfo   = '{indir}/annotation/{name}/attributes/seqinfo.fa',

        # Optional columns of the table
        attrs_blast         =  blast_attr_tsvs                                         if include_blast     else [],
        attrs_coverage      = '{indir}/annotation/{name}/attributes/coverage.tsv'      if include_coverage  else [],
        attrs_mapped_reads  = '{indir}/annotation/{name}/attributes/mapped_reads.tsv'  if include_coverage  else [],
        attrs_virfinder     = '{indir}/annotation/{name}/attributes/virfinder.tsv'     if include_virfinder else [],

    output:
        html  = '{indir}/annotation/{name}/summary.html',
        tsv   = '{indir}/annotation/{name}/summary.html.tsv'
    params:
        fasta = 'sequences/all_contigs.fa',
        max_query_seqs = method_config.get('max_query_seqs', None),
        seqs_per_page = method_config['html'].get('seqs_per_page', 100),
        sort_by = method_config['html'].get('sort_by', ''),
        sort_how = method_config['html'].get('sort_how', 'asc'),
        fasta_dir = 'sequences',
        html_columns = method_config['html'].get('columns', [])
    run:
        def flatten(files):
            flat = []
            for item in files:
                if item:
                    if type(item) == snakemake.io.Namedlist:
                        flat.extend(item)
                    else:
                        flat.append(item)
            return flat

        def load_attrs(attr_file):
            table = pd.read_csv(attr_file, sep='\t', index_col=0)
            return table

        attr_files = flatten([attr_file for name, attr_file in input.__dict__.items() if name.startswith('attrs_')])
        attr_names = [os.path.basename(f)[:-4] for f in attr_files]
        attr_tables = [load_attrs(attr_file) for attr_file in attr_files]

        attrs, last_name = attr_tables[0], attr_names[0]
        for attr_name, attr_table in zip(attr_names[1:], attr_tables[1:]):
            attrs = attrs.merge(attr_table, how='outer',
                                left_index=True, right_index=True)
            last_name = attr_name

        attrs.sort_values(by='Length', ascending=False, inplace=True)
        if params.max_query_seqs:
            attrs = attrs.iloc[:int(params.max_query_seqs)]


        # TSV report
        tsv_columns = [attr for attr in attrs.columns if ' link' not in attr]
        attrs[tsv_columns].to_csv(output.tsv, sep='\t')

        # HTML report
        TEMPLATE = open(input.template).read()
        with open(output.html, 'w') as out:
            attrs['Sequence'] = ['<a href="%s/%s.fa">%s</a>' % (params.fasta_dir, seqid, i+1) \
                                        for i, seqid in enumerate(attrs.index)]
            attrs.index = np.arange(1, len(attrs) + 1)

            html_columns = attrs.columns
            if params.html_columns:
                html_columns = []
                for col_prefix in params.html_columns:
                    html_columns.extend(sorted([col for col in attrs.columns if col.startswith(col_prefix)]))

            html_attrs = attrs[html_columns]
            html_table = html_attrs\
                            .fillna('') \
                            .to_html(escape=False, index=False) \
                            .replace('<table ', '<table id="data" ')

            sort_index = list(html_attrs.columns).index(params.sort_by)
            out.write(TEMPLATE.format(attrs=html_table,
                                      seq_fasta=params.fasta,
                                      sort_index=sort_index,
                                      sort_how=params.sort_how,
                                      seqs_per_page=params.seqs_per_page))

