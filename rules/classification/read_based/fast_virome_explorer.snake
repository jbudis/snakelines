include: config['snakelines_dir'] + '/rules/mapping/index/samtools.snake'

# Import python libraries
import shutil
import pandas as pd
from Bio import SeqIO


count_type = method_config['count_type']
if count_type == 'read_count':
    count_suffix = ''
elif count_type == 'tpm':
    count_suffix = '_tpm'
else:
    assert 'Unknown count type {count_type}. Use read_count or tpm.'


rule fast_virome_explorer__estimate_virome_composition:
    """
    Asses viral composition of sample based on read_counts of particular taxonomic units.
    :input reads_f: fastq file with sequences from forward strand
    :input reads_r: fastq file with sequences from reverse strand
    :input index: kallisto index created from reference database
    :input ref_lens: lenghts of particular reference genomes from database
    :output composition: TSV table containing information about number of reads assigned to taxonomic units (most common species)
    :output abundance: TSV table containing NCBI ID of all found taxonomic units with assigned read counts and transkripts per milion
    :params outdir: output directory for fast_virome_explorer
    :params cr: ratio of coverages parameter
    :params co: genome coverage parameter
    :params cn: mapped reads paramater
    """
    input:
        reads_f     = 'reads/%s/{sample}_R1.fastq.gz' % pipeline.preprocessed_read_type,
        reads_r     = 'reads/%s/{sample}_R2.fastq.gz' % pipeline.preprocessed_read_type,
        index       = 'reference/{{reference}}/kallisto_index/{{reference}}-k{kmer_size}.idx' \
                            .format(kmer_size=method_config['kmer_size']),
        ref_lens    = 'reference/{reference}/kallisto_index/{reference}.lens.txt'
    output:
        composition = 'classification/{reference}/{sample}/FastViromeExplorer-final-sorted-abundance.tsv',
        abundance   = 'classification/{reference}/{sample}/abundance.tsv'
    log:
        out         = 'classification/{reference}/{sample}/log/{sample}.log', # log report from fast virome explorer tool
        err         = 'classification/{reference}/{sample}/log/{sample}.err'  # error report from fast virome explorer tool
    params:
        outdir      = 'classification/{reference}/{sample}',                  # ouput directory, necessary for fast virome explorer
        cr = method_config['ratio_of_coverages'],
        co = method_config['genome_coverage'],
        cn = method_config['mapped_reads']
    conda:
        config['snakelines_dir'] + '/enviroments/others_env.yaml'
    shell:
        '''
        fast_virome_explorer \
            -1 {input.reads_f} \
            -2 {input.reads_r} \
            -i {input.index} \
            -o {params.outdir} \
            -l {input.ref_lens} \
            -cr {params.cr} \
            -co {params.co} \
            -cn {params.cn} \
         > {log.out} \
        2> {log.err}
        '''


rule custom__convert_to_tpm_metric:
    """
    Python script (have to be set in config => count_type: tpm),
    Create new TSV table with metric turned into tpm (transcripts per milion).
    :input checked_composition: checked TSV table in previous rule, containing information about number of reads
                                assigned to taxonomic units (most common species)
    :input abundance: TSV table containing NCBI ID of all found taxonomic units with assigned read counts and
                      transcripts per milion, output from rule fast_virome_explorer__estimate_virome_composition
    :input py_script: path to  python script
    :output checked_tpm_composition: new TSV table but that count metric is changed from read count to tpm
    """
    input:
        checked_composition     = 'classification/{reference}/{sample}/FastViromeExplorer-final-sorted-abundance.tsv',
        abundance               = 'classification/{reference}/{sample}/abundance.tsv',
        py_script               = srcdir('fast_virome_explorer/create_tpm_for_krona.py')
    output:
        checked_tpm_composition = 'classification/{reference}/{sample}/FastViromeExplorer-final-sorted-abundance_tpm.tsv'
    shell:
       'python3 {input.py_script} {input.checked_composition}'


rule custom__convert_to_krona:
    """
    Create from input file new krona file.
    :input composition: containing information about number of reads assigned to taxonomic units (most common species),
                        output file from one of the last two previous rules (according to selected count metric)
    :output krona: new krona file
    """
    input:
        composition = 'classification/{{reference}}/{{sample}}/FastViromeExplorer-final-sorted-abundance{count_suffix}.tsv'\
                            .format(count_suffix=count_suffix)
    output:
        krona       = 'classification/{reference}/report/krona/individual/{sample}.krn'
    run:
        viruses = pd.read_csv(input.composition, sep='\t', index_col=0)
        with open(output.krona, 'w') as out:
            if len(viruses) > 0:
                tax_column = viruses.columns[1]
                for _, virus in viruses.iterrows():
                    out.write('{abundance}\t{tax}\n'.format(abundance=virus.EstimatedAbundance,
                                                            tax=virus[tax_column].replace(';', '\t')))
            else:
                out.write('1\tNomatch\n')


rule kallisto__prepare_index:
    """
    Index fasta file to quick identify source of input sequenced reads
    :input reference: Genomic sequence file in fasta format to index
    :output index: Index for the input reference genomic file
    """
    input:
        reference = 'reference/{reference}/{reference}.fa'
    output:
        index     = 'reference/{reference}/kallisto_index/{reference}-k{kmer_size}.idx'
    shell:
        """
        kallisto index \
            --index {output.index} \
            --kmer-size {wildcards.kmer_size} \
            {input.reference}
        """


rule custom__prepare_read_lens:
    """
    Create TSV file with lengths of reference sequences, required for FVE analysis
    :input reference: Genomic sequence file in fasta format to index
    :input taxes: Taxonomy file in TSV format (each line represent a single reference sequence)
    :output lens: TSV file with lengths of reference sequences
    """
    input:
        reference = 'reference/{reference}/{reference}.fa',
        taxes     = 'reference/{reference}/{reference}.tax'
    output:
        lens      = 'reference/{reference}/kallisto_index/{reference}.lens.txt'
    run:
        taxes = pd.read_csv(input.taxes, sep='\t', index_col=0, header=None)[1]

        with open(output.lens, 'w') as out:
            for seq in SeqIO.parse(input.reference, 'fasta'):
                out.write('{seq_id}\t{seq_name}\t{tax}\t{length}\n'.format(seq_id=seq.id, seq_name=seq.description,
                                                                           tax=taxes[seq.id], length=len(seq)))

