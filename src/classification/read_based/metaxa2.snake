include: config['snake_dir'] + '/reads/conversion/unzip.snake'

from glob import glob
import pandas as pd

# TODO: Comment rules

rule metaxa2__classify_reads:
    input:
        r1           = 'reads/%s/{sample}_R1.fastq.gz' % pipeline.preprocessed_read_type,
        r2           = 'reads/%s/{sample}_R2.fastq.gz' % pipeline.preprocessed_read_type,
        blast        = 'reference/{reference}/metaxa2_index/blast.nhr',
        cutoffs      = 'reference/{reference}/metaxa2_index/blast.cutoffs.txt',
        hmm          = 'reference/{reference}/metaxa2_index/HMMs/E.hmm'
    output:
        taxonomy     = 'classification/{reference}/samples/{sample}/{sample}.taxonomy.txt'
    params:
        outpref      = 'classification/{reference}/samples/{sample}/{sample}',
        hmm_dir      = 'reference/{reference}/metaxa2_index/HMMs',
        blast_prefix = 'reference/{reference}/metaxa2_index/blast',
        confidence = int(100*float(tool_config.get('confidence', 0.8)))
    log:
        out          = 'classification/{reference}/samples/{sample}/log/metaxa2.log',
        err          = 'classification/{reference}/samples/{sample}/log/metaxa2.err'
    threads:
        int(config['threads'])
    shell:
        '''
        metaxa2 \
            -1 {input.r1} \
            -2 {input.r2} \
            --format p \
            -o {params.outpref} \
            -g {wildcards.reference} \
            -R {params.confidence} \
            -p {params.hmm_dir} \
            -d {params.blast_prefix} \
            -T {input.cutoffs} \
            --plus T \
            --cpu {threads} \
        >  {log.out} \
        2> {log.err}
        '''


rule metaxa2__create_reference_index:
    input:
        fasta     = 'reference/{reference}/{reference}.fa',
        tax       = 'reference/{reference}/{reference}.tax'
    output:
        blast     = protected('reference/{reference}/metaxa2_index/blast.nhr'),
        cutoffs   = protected('reference/{reference}/metaxa2_index/blast.cutoffs.txt'),
        hmm       = protected('reference/{reference}/metaxa2_index/HMMs/E.hmm'),
    params:
        index_dir = 'reference/{reference}/metaxa2_index'
    threads:
        int(config['threads'])
    log:
        out       = 'reference/{reference}/metaxa2_index/log/db.log',
        err       = 'reference/{reference}/metaxa2_index/log/db.err'
    shell:
        '''
        metaxa2_dbb \
            -i {input.fasta} \
            -o {params.index_dir} \
            -g {wildcards.reference} \
            -t {input.tax} \
            --auto_rep T \
            --cpu {threads} \
            --plus T \
         > {log.out} \
        2> {log.err}
        '''


rule metaxa2__summarize_classification:
    input:
        nomatch_template     = srcdir('metaxa2/nomatch.txt'),
        nomatch_tax_template = srcdir('metaxa2/nomatch.level_7.txt'),
        taxonomy             = 'classification/{reference}/samples/{sample}/{sample}.taxonomy.txt',
    output:
        summary              = 'classification/{reference}/samples/{sample}/{sample}.level_7.txt',
    params:
        outpref              = 'classification/{reference}/samples/{sample}/{sample}',
        nomatch_taxonomy     = 'classification/{reference}/samples/{sample}/{sample}.taxonomy.nomatch.txt'
    log:
        out                  = 'classification/{reference}/samples/{sample}/log/metaxa2_ttt.log',
        err                  = 'classification/{reference}/samples/{sample}/log/metaxa2_ttt.err'
    shell:
        '''
        TAXONOMY={input.taxonomy}
        if [ ! -s {input.taxonomy} ];
        then
            cp {input.nomatch_template} {params.nomatch_taxonomy}
            TAXONOMY={params.nomatch_taxonomy}
            echo $TAXONOMY
        fi
        metaxa2_ttt \
                -i $TAXONOMY \
                -o {params.outpref} \
        >  {log.out} \
        2> {log.err}

        if [ ! -f {output.summary} ];
        then
            cp {input.nomatch_tax_template} {output.summary}
        fi
        '''



rule metaxa2__prepare_for_krona:
    input:
        classification = 'classification/{reference}/samples/{sample}/{sample}.level_7.txt'
    output:
        krona          = 'classification/{reference}/report/krona/individual/{sample}.krn'
    run:

        def most_specialized_classification(wildcards):

            def get_class_level(class_file):
                level = class_file.split('_')[-1].split('.')[0]
                return int(level)

            class_files = glob('classification/{reference}/samples/{sample}/{sample}.level_*.txt'.format(
                                reference=wildcards.reference, sample=wildcards.sample))

            return sorted(class_files, key=get_class_level)[-1]

        invalid_tags = ['unclassified', 'unknown', 'uncultured']

        def is_informative(taxon):
            for tag in invalid_tags:
                if tag in taxon.lower():
                    return False
            return True

        def to_krona_format(tax):
            items = tax.strip(';').split(';')
            for i, item in enumerate(items):
                if not is_informative(item):
                    items = items[:i]
                    break
            return '\t'.join(items)

        counts = pd.read_csv(most_specialized_classification(wildcards), sep='\t', header=None)
        counts.columns = ['tax', 'reads']
        counts['tax_refined'] = counts['tax'].apply(to_krona_format)

        with open(output.krona, 'w') as out:
            for _, row in counts.iterrows():
                out.write('{row.reads}\t{row.tax_refined}\n'.format(row=row))
